\section*{Hypothesis}
Our hypothesis is that parallelising our code through colouring and running each colour on the GPU simultaneously will provide a massive performance increase.


GPGPU (General-purpose graphics processing unit) is `the utilisation of a graphics processing unit (GPU), which typically handles computation only for computer graphics, to perform computation in applications traditionally handled by the central processing unit (CPU)' \cite{gpgpu}.
GPU's are ideal for the smoothing algorithm that we have been provided with since although they can only process independent vertices and fragments they can process many of them in parallel and achieve SIMD performance. The transistors of a GPU are devoted to data processing(mainly integer and floating point)\cite{lec7}.

% TODO: WRITE A BIT FROM http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html - hardware impl section

Since we can colour our mesh and run vertices of the same colour on in parallel the GPU seems like a natural choice for optimisation. Furthermore the smoothing algorithm makes use of many floating point operations and so we should see a very large speed up from just porting to the CPU alone.

The CUDA Toolkit provides a comprehensive development environment and allows for easy migration of code.

\input{hypothesis/coloring}
\input{hypothesis/migration}

It is however, not enough to stop at just running the code on our GPU. We must also then optimise for the GPU to achieve maximum performance. Therefore we propose the following.

\input{hypothesis/branching}
\input{hypothesis/pinning}
\input{hypothesis/thread_size}
\input{hypothesis/batch_transfer}