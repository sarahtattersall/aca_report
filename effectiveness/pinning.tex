\subsection{Pin data for transfer}
With a pinning pre-processing step (which simulates the host always using pinned data), we avoid the cost of of the transfer between pageable and pinned host memory and see the following speed up.
\begin{figure}[H]\centering \begin{tabular}{ l | l }
  \hline
  Size & Average Over Three Time (s) \\
  \hline
  \hline
  small & 2.05 \\
  medium & 14.64 \\
  \hline
\end{tabular} \end{figure}

Pinning our memory has made a slight difference to the performance of our run and we expect with larger amounts of data would make more of a difference, since the GPU no longer needs to pin the memory before transfer.

Unfortunately we wished to profile the results of this change to our code, but the CUDA command line profiler stopped working. In order to track down the bug we reverted back to using the \verb!std::vector!'s to copy from host to device. We then ran our pinning code (which should be `\emph{dummy}', i.e. that it pins the data to the arrays but has no effect on the GPU since it is not used anywhere). We found even with pinning that should in theory do nothing the profiler would not produce any output. Furthermore we narrowed it down to the \verb!cudaHostAlloc! function calls being commented in/out and which toggled whether the profiler produced an output or not.
To track the bug down further we created a small example of the problem in order to post it online on Stack Overflow. However the small example worked with calls to \verb!cudaHostAlloc! and so we have been unable to find the problem. The Stack Overflow question we posted is still open.~\cite{so_profiler}