\section{Conclusion}
Porting the code to a GPU really does provide vast speed ups of the code. The impact is distinctly pronounced in the case of the \texttt{medium.vtu} and \texttt{large.vtu} meshes, which take a very long time to run on the CPU.
In particular, it is parallelisation that this algorithm specifically benefits from. Although we did not compare our initial GPU results with a parallelised version running on the CPU (i.e. coloured), there is little to no question that it will run faster as the GPU supports far faster floating point manipulations, and a significantly higher number of threads than the CPU.

The CUDA Tool Kit has come a long way in the past few years, providing an easy and relatively straightforward introduction into GPU programming even with no prior GPU programming experience. The use of CUDA benefitted this project's timescale, in a contrast with its less restrictive counter-part, OpenCL, due to the experience level of the group members.

Furthermore the optimisations to the GPU did, on the whole, provide for better performance, with a notable exception being re-ordering the colours, whose lack of contribution was easy to reason about using profiling.

A major restriction to this project was making the decision to not run our code on cx1. Again, given the timescale, this was the correct decision to make as it allowed us to make quick iterative improvements to the code. The down side, however, was having a GPU with compute capacity of 1.0, which seriously restricted the available profiling and thus our ability to reason about performance bottlenecks without speculation.
Additionally, had we used a GPU with compute capability $\ge$ 2.0 then the GPU would have had 32 cores \cite{compute_2.0}, as opposed to only 8, and the performance of the algorithm is likely to have been substantially better due to the large number of vertices in each colouring.
